{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### [1] Concept of framework:\n",
    "- Bayesian inference is reallocation of probabilities across possibilities\n",
    "- Possibilities are parameter values (a, u, o) in meaningful mathmatical models N(u, a)\n",
    "\n",
    "### [2] Steps of Bayesian Data Analysis:\n",
    "\n",
    "- (1) Indentify data -> measurement, scale, predictor, target\n",
    "- (2) Define a mathmatical form / parameters to describe in appropriate theoretical purpose\n",
    "- (3) Spcify a prior distribution on parameters\n",
    "- (4) Use Bayesian inference to re-allocate probabilities across parameter values and generate postieror distribution\n",
    "- (5) Check the posterior prediction under reasonable accuracy\n",
    "\n",
    "### [3] What is Probability?\n",
    "- Sample space – A set of outcome exhausted all possibilities and mutually exclusive\n",
    "- Probability – is a way of assigning numbers to a set of mutually exclusive possibilities\n",
    "- Probability Distribution – A set of all possibilities and their corresponding probabilities\n",
    "-      (1) Discrete Outcomes (Probability Mass)\n",
    "-      (2) Continuous Outcomes (Probability Density)\n",
    "- Probability Density Function – Any function that has only nonnegative values and integrates to 1can be constructed as a probability density function\n",
    "- Expected Value of a Distribution – Weight each outcome value with Prod()  them sum up, usually “mean”\n",
    "\n",
    "\n",
    "### [4] Bayes' Rule\n",
    "- P ( Theta | Data )   =   P ( Data | Theta )    *   P ( Theta )   /   P ( Data )\n",
    "- Posterior Probability   =   Likelihood   *   Prior    /   Evidence ( Marginal Likelihood ) \n",
    "\n",
    "\n",
    "### [5] How to do Bayesian Inference?\n",
    "\n",
    "- (1) Conjugate Prior – Mathematical update from prior to posterior, prior distribution the same as posterior distribution\n",
    "\n",
    "- (2) Grid Approximation – Not all prior can be expressed in a conjugate prior, we can create a grid to discrete values over Theta, Create value of this binned “Mass function”. Can still be difficult if there are multiple Thetas\n",
    "\n",
    "- (3) Markov Chain Monte Carlo (MCMC) – {MC} – each step is independent, {MC} – Assessing properties of a target distribution by generating representative random values. Approximating a posterior distribution by collecting a large representative sample from it. \n",
    "\n",
    "##### Assumption: \n",
    "prior distribution specified by function; likelihood specified by function; Both can be easily computed up to a multiplicative constant \n",
    "##### Result: \n",
    "an approximation of posterior distribution P ( Theta | data )\n",
    "\n",
    "##### Algorithms: \n",
    "\n",
    "###### Metropolis: \n",
    "\n",
    "Step1 – Pick an arbitrary initial Theta or {Theta[ij]}\n",
    "\n",
    "Step2 – Based on an proposal distribution – propose a move, tune sd, fewer \n",
    "steps to converge \n",
    "\n",
    "Step3 – If P(D|theta-new)*P(theta-new) > P(D|theta-old)*P(theta-old) then move theta to theta-new; else then randomly select # from [0-1], if # between [0, P(D|theta-new)*P(theta-new) / P(D|theta-old)*P(theta-old)], then move theta to theta-new, else then stay theta-old.\n",
    "\n",
    "##### Gibbs Sampling:\n",
    "\n",
    "Good for multiple parameters, hierarchy model \\ limit (high correlated parameters)\n",
    "\n",
    "Step1 – Pick a an arbitrary initial value point of combination theta[ij] \n",
    "\n",
    "Step2 – from theta[ij] circle through each of them, select theta[ij=1] then generate random value from conditional probability distribution P( theta[ij=1] | theta[ij<>1], D ) ** proposal distribution mimic posterior\n",
    "Step3 – use theta-new[ij=1] + theta-old[ij<>1] as proposed theta move\n",
    "Step4 – same as Metropolis\n",
    "\n",
    "###### Hamiltonian Monte Carlo (HMC):\n",
    "\n",
    "Good for large complex models\n",
    "Variation of “Metropolis” – Different proposal distribution that changes depends on the current position. HMC figures out the direction in which the posterior distribution increases, called its gradient, and warps the proposal distribution towards the gradient.\n",
    "\n",
    "##### Evaluate / Optimization on MCMC Process\n",
    "- Process:\n",
    "\n",
    "Step1 – Initiate Chains\n",
    "\n",
    "Step2 – Generate Chains\n",
    "\n",
    "Step3 – Examine the Chains\n",
    "\n",
    "Step4 – Shows MCMC sample from the posterior distribution\n",
    "\n",
    "- Measurement:\n",
    "\n",
    "Trace Plot – Good overlap of chains – burn-in\n",
    "\n",
    "Density Plot – Plot dist of each chains, 95HDI overlap\n",
    "\n",
    "Autocorrelation Plot – “How clumpy?”, very close to each\n",
    "\n",
    "Shrink Factor Plot - ??, close to each\n",
    "\n",
    "### [6] How to evaluate performance - Goal, Power, Sample Size?\n",
    "\n",
    "###### Statistical Power – \n",
    "\n",
    "Is the probability of achieving the goal of a planned empirical study, if a suspected underlying state of the world is true, (1) unachievable – Don’t waste time. (2) Easily achievable – Don’t sample too much. ** Traditional NHST in multiple tests, Power decreases while in Bayesian, power stable because it totally based on data \n",
    "\n",
    "##### Goals and Obstacles – \n",
    "\n",
    "Goals: (1) Reject a null value of a parameter; (2) Affirm a predicted value of a parameter ([ROPE] included in HDI); (3) Achieve precision in the estimation of parameter (HDI width less than a threshold) \n",
    "\n",
    "Obstacles: random sample is only a probabilistic representation of the real world. Noises are the enemies.\n",
    "\n",
    "##### Power – \n",
    "\n",
    "Since the random noises, the goal can only be achieve probabilistically. The probability of achieving the goal, given the state-of-the world and sampling plan, is called “Power” of the planned research  **Traditional NHST – power’s only goal rejecting null \n",
    "\n",
    "- Ways to increase the power: (1) Control on co-founder to detect noisy; (2) Increase underlying effect – increase test effect; (3) Increase sample size\n",
    "\n",
    "##### Power Analysis – \n",
    "\n",
    "Hypothesis Parameter distribution (Good if summarized from previous data) Sample a Parameter value Use that Parameter value to simulate the sampling data (Like the planned sampling process)  Prior ~ Likelihood ~ Posterior  Evaluate of all iterations ?% achieved the goal = ex. 70% the power  **Only useful when simulated data close to real data\n",
    "\n",
    "###### Sample Size – \n",
    "More sample size, more power | It increase the precision NOT the value, if False, more data can’t change.\n",
    "\n",
    "##### Sampling Bias: \n",
    "No Bias (Sample N cases); Biased (Sample Z success events); No Bias (Sample cases for M hours)\n",
    "\n",
    "##### Other Expressions of Goals – \n",
    "Ways to express mathematically the goal of precision in estimation (Not using power)\n",
    "\n",
    "- Average Length Criterion – Average width of the 95HDI in posterior\n",
    "\n",
    "- Average Coverage Criterion – % of Iteration Given specific width of HDI, require its Mass exceeds 95%\n",
    "\n",
    "- Entropy of a distribution – Average entropy (The more spread a distribution the bigger the entropy) – Higher precision, low entropy\n",
    "\n",
    "##### Other Expressions of Goals – \n",
    "Ways to express mathematically the goal of excluding a Null value\n",
    "\n",
    "- Sufficient large Bayes Factor (BF) – Average of BF from posterior\n",
    "\n",
    "- How often % HDI excludes ROPE - % confidence to reject null\n",
    "\n",
    "\n",
    "##### Sequential Testing\n",
    "Keep sampling while using these metrics as “Stopping Rule” (P-value, Criterial BF, HDI-ROPE, Precision)\n",
    "\n",
    "- P-Value: Always eventually reject null even if null is true (100% fa)\n",
    "- Criterial BF: No 100% fa when null is true, yet, also falsely accept when null is not true\n",
    "- HDI_ROPE: No 100% fa when null is true, No falsely accept\n",
    "- Precision (HDI_Width): Never fa, but may be uncertain in some case\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAGS - Software\n",
    "\n",
    "xxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------- R\n",
    "\n",
    ">>>>>>>>> JAGS \n",
    "install.packages(\"rjags\")\n",
    "install.packages(\"runjags\")\n",
    "library(rjags);library(runjags)\n",
    "\n",
    "# Load data\n",
    "myData = read.csv(\"xxx.csv\")\n",
    "y = myData$y\n",
    "Ntotal = length(y)\n",
    "dataList = list(\n",
    "\ty = y,\n",
    "\tNtotal = Ntotal\n",
    "\t)\n",
    "\n",
    "# Specify the model\n",
    "modelString = \"\"\" # open quote for modelString\n",
    "   model {\n",
    "   \tfor ( i in 1:Ntotal ) {\n",
    "   \t\ty[i] ~ dbern( theta ) \n",
    "   \t}\n",
    "   \ttheta ~ dbeta( 1 , 1 )\n",
    "   }\n",
    "\n",
    "\"\"\"\n",
    "writeLines(modelString, con=\"TEMPmodel.txt\") # write to file\n",
    "\n",
    "# Initialize chains\n",
    "initsList = function() {\n",
    "\tresampledY = sample(y, replace=T)               # resample values from y\n",
    "\tthetaInit = sum(resampledY)/length(resampledY)  # compute proportion (MLE)\n",
    "\tthetaInit = 0.001+0.998*thetaInit               # keep away from 0, 1\n",
    "\treturn(list(theta=thetaInit))                   # return as a named list\n",
    "}\n",
    "\n",
    "# Generate chains\n",
    "jagsModel = jags.model(file=\"TEMPmodel.txt\", \n",
    "\t                   data=dataList, \n",
    "\t                   inits=initsList,\n",
    "\t                   n.chains=3,\n",
    "\t                   n.adapt=500)\n",
    "\n",
    "update(jagsModel, n.iter=500) # run chains for number of steps\n",
    "\n",
    "# Tell JAGs to generate MCMC sample we used to represent the posterior distribution\n",
    "codaSamples = coda.samples(jagsModel, variable.names=c(\"theta\"), n.iter=3334) \n",
    "\n",
    "# Exame Chains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------- Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAN - Software\n",
    "\n",
    "xxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------- R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------- Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------ [Hierarchical Models]\n",
    "\n",
    "###### Hierarchical Model - \n",
    "HM are mathematical descriptions involving multiple parameters such that the credible values of some parameters meaningfully depend on the values of other parameters\n",
    "\n",
    "###### Why very effective? – \n",
    "estimate of each individual parameter is simultaneously informed by data from all other individuals. All individual inform the higher level parameter – constrain all individual parameters \n",
    "\n",
    "##### Parameters at different levels in a hierarchical model \n",
    "are all merely parameters that coexists in a joint parameter space, we simply apply Bayes’ rule to the joint parameters space ----- P ( Theta1, Theta2, beta1, beta2 | Data ) = P ( Data | Theta1) * P ( Theta1 | Theta2 ) * P ( theta2 | beta1 ) * P ( beat1 | beta2) * P ( beta2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example 1 – Single Coin from a Single Mint\n",
    "\n",
    "Y[i]: [1,1,0,1,0, …, 1]\n",
    "\n",
    "For every Y in [i] generated from distribution “dbern(Theta)”  \n",
    "\n",
    "“Theta” generated from distribution “Beta(w,k)”\n",
    "\n",
    "“w” generated from “Beta(Aw, Bw)”\n",
    "\n",
    "“k” generated from “Gamma(Sk,Rk)”\n",
    "\n",
    "Aw, Bw, Sk, Rk are constant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 – Multiple Coins(s) from a Single Mint\n",
    "\n",
    "Y1[i]: [1,1,0,1,0, …, 1] … Ys[i]: [1,1,0,1,0, …, 1] \n",
    "\n",
    "For every Y in [i|s] generated from distribution “dbern(Theta[s])”  \n",
    "\n",
    "For every “Theta” in [s] generated from distribution “Beta(w,k)”\n",
    "\n",
    "“w” generated from “Beta(Aw, Bw)”\n",
    "\n",
    "“k” generated from “Gamma(Sk,Rk)”\n",
    "\n",
    "Aw, Bw, Sk, Rk are constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3 – Multiple Coins(s) from a Multiple Mints(c)\n",
    "\n",
    "Y1|1[i]: [1,1,0,1,0, …, 1] … Ys|c[i]: [1,1,0,1,0, …, 1]\n",
    "\n",
    "For every Y in [i|s,c] generated from distribution “dbern(Theta[s|c])”  \n",
    "\n",
    "For every “Theta” in [s|c] generated from distribution “Beta(w[c],k[c])”\n",
    "\n",
    "For every “w” in [c] generated from “Beta(Aw, Bw)”\n",
    "\n",
    "For every  “k” in [c[ generated from “Gamma(Sk,Rk)”\n",
    "\n",
    "Aw, Bw, Sk, Rk are constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4 – Model Comparison \n",
    "\n",
    "Re-allocate credibility across models – Top-level parameter model index [m] evenly distributed\n",
    "\n",
    "A model = likelihood function  *  Prior Distribution  \n",
    "\n",
    "Define by Bayes Factor (BF) – P(D|M=1) / P(D|M=2) **Probability of data in M1, M2\n",
    "\n",
    "Sensitive to prior choice:\n",
    "\n",
    "- Choice 1: Parameters for all Ms in joint space\n",
    "- Choice 2: Likelihood, prior sep(M for M)\n",
    "- Choice 3: Prior sep(M for M) but likehood the same\n",
    "\n",
    "###### Evaluation1 – Conjugate BF: \n",
    "\n",
    "Posterior Odd – P (M=1|D) / P (M=2|D)\n",
    "\n",
    "Bayes Factor – P (D|M=1) / P (D|M=2) \n",
    "\n",
    "Prior Odd – P (M=1) / P (M=2)\n",
    "\n",
    "Posterior Odd = BF * Prior Odd\n",
    "\n",
    "Conjugate BF – P(z,n) = P(z+a,n-z+b) = P (D|M)\n",
    "\n",
    "Calculate Posterior Odd = 0.213\n",
    "\n",
    "Since SUM(p(m[i]|D)) = 1, so P(M=1|D)/(1-P(M=1|D)) = 0.213, P(M=1|D) = 17.6%, P(M=2|D) = 1 – 17.6% = 82.4%\n",
    "\n",
    "##### Evaluation2 - \n",
    "MCMC: prior M = 0.5/0.5, then posterior distribution of index [m], ?/? which more likely?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------ [Hull Hypothesis Significance Testing]\n",
    "\n",
    "##### NHST (Frequentist): \n",
    "P-value, is the probability of getting an sample outcome from the hypothesis population (t/z-distribution) that is as extreme as or more extreme than the actual outcome (data) when using the intended sampling and testing process\n",
    "\n",
    "##### NHST (Bayesian): \n",
    "Doesn’t depend on intension of testing / collecting. Assume data independent across each other. So, the probability of the set of the data is simply the product of probability of the individual outcome. [likelihood] * [prior] = [posterior] -> check HDI contains null | Check “BF”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Example 1 – One sample Tests\n",
    "\n",
    "- Estimation Approach\n",
    "\n",
    "[Likelihood] * [Prior]  MCMC  [Posterior]\n",
    "\n",
    "If [HDI] not contain [ROPE]-null  Reject\n",
    "\n",
    "If [HDI] contain [ROPE]-null  Accept\n",
    "\n",
    "If [HDI] contain by [ROPE]-null  Accept (weak)\n",
    "\n",
    "If [HDI] overlap with [ROPE]-null  Not Clear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model-Comparison Approach\n",
    "\n",
    "M1: [Likelihood D]  *  [Prior - null]\n",
    "\n",
    "M2: [Likelihood D]  *  [Prior – alter]\n",
    "\n",
    "Posterior Odd  = BF * Prior Odd\n",
    "\n",
    "Posterior Odd = 0.342\n",
    "\n",
    "Since SUM(p(m[i]|D)) = 1, so P(M1|D)/(1-P(M1|D)) = 0.342\n",
    "\n",
    "P(M=1|D) = 27.6%\n",
    "\n",
    "P(M2|D) = 1 – 27.6% = 72.4%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2 – Two or more sample[s] Tests\n",
    "\n",
    "- Estimation Approach\n",
    "\n",
    "Hierarchical Model - like [Multiple coins[s] from single mint]\n",
    "\n",
    "[Posterior]: Theta1_Theta2_Diff -> [HDI] vs {ROPE-null:0] ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model-Comparison Approach\n",
    "\n",
    "M1: each group has distinct Theta[s]\n",
    "\n",
    "M2: all groups share one Theta0\n",
    "\n",
    "MCMC -- [Posterior]-M distribution -> Which M more creditable?\n",
    "\n",
    "BF (M1, M2) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------------------ [The Generalized Linear Models]\n",
    "\n",
    "This family of models comprises the traditional “off the shell” analyses such as T Test, ANOVA, Multiple Linear Regression, Logistic, Log-linear Models, etc.\n",
    "\n",
    "- X,Y (Type) – Metric(1-infinite), Ordinal(1,2,3), Nominal(A,B,C), Count(12,45,31) \n",
    "\n",
    "- Metric = Y~Normal(u,a)\\T(v,u,a)\n",
    "\n",
    "- Dichotomous = Y~Bernoulli(u)\n",
    "\n",
    "- Nominal = Y~MASS_DIS(…u[j]….)\n",
    "\n",
    "- Ordinal = Y~MASS_DIS(…u[j]….)\n",
    "\n",
    "- Count = Y~Poisson(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [1] Metric Predicted Variable on One or Two Groups\n",
    "\n",
    "T-Distribution -> metric (Robust than Normal-Distribution)\n",
    "\n",
    "Z-Distribution -> Ratio\n",
    "\n",
    "###### One Group: \n",
    "\n",
    "Y[i] distributed by T-distribution(v,u,a)\n",
    "\n",
    "v distributed by Exp(K)\n",
    "\n",
    "u distributed by N(M,S)\n",
    "\n",
    "a distributed by Uni(L,H)\n",
    "\n",
    "v,u,a are Constants\n",
    "\n",
    "Evaluation: MCMC Posterior(u) HDI vs Null value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Two Groups: \n",
    "\n",
    "Y[i]|j distributed by T-distribution(v[j],u[j],a[j])\n",
    "\n",
    "For v in jth distributed by Exp(K)\n",
    "\n",
    "For u in jth distributed by N(M,S)\n",
    "\n",
    "For a in jth distributed by Uni(L,H)\n",
    "\n",
    "v,u,a are Constants\n",
    "\n",
    "Evaluation: MCMC Posterior(u[1]_u[2]_Diff) HDI vs 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [2] Metric Predicted Variable with One Metric Predictor\n",
    "\n",
    "Simple Linear Regression 1X\n",
    "\n",
    "Y[i] distributed by T-distribution(v,u[i],a)\n",
    "\n",
    "u[i] calculated from ( beta0 + beta1*x[i] )\n",
    "\n",
    "beta0 distributed by N(M0,S0)\n",
    "\n",
    "beta1 distributed by N(M1,S1)\n",
    "\n",
    "v distributed by Exp(K)\n",
    "\n",
    "a distributed by Uni(L,H)\n",
    "\n",
    "M0, S0, M1, S1, u, a are Constants\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[i]) of ith Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3] Metric Predicted Variable with Multiple Metric Predictors\n",
    "\n",
    "Multiple Linear Regression [j] Xs\n",
    "\n",
    "Y[i] distributed by T-distribution(v,u[i],a)\n",
    "\n",
    "u[i] calculated from ( beta0 + beta[j]*x[i|j] )\n",
    "\n",
    "beta0 distributed by N(M0,S0)\n",
    "\n",
    "For beta in jth distributed by N(M[j],S[j])\n",
    "\n",
    "v distributed by Exp(K)\n",
    "\n",
    "a distributed by Uni(L,H) **Assume variance the same\n",
    "\n",
    "M0, S0, M[j], S[j], u, a are Constants\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[i]) of ith Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [4] Metric Predicted Variable with One Nominal Predictor\n",
    "\n",
    "- One-Way ANOVA: beta0 + beta1[j] X(nominal)\n",
    "\n",
    "Y[i] distributed by N(u[i],ay)\n",
    "\n",
    "u[i] calculated from beta0 + beta1[j] X[i](nominal)\n",
    "\n",
    "beta0 distributed by N(M0, S0)\n",
    "\n",
    "For beat1 in jth distributed by N(0, a-beta1)\n",
    "\n",
    "ay distributed by Uni(L, H)\n",
    "\n",
    "L, H, M0, S0 are constants\n",
    "\n",
    "a-beta1 is constant / small-strong shrinkage\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[A]_u[B]_Diff) HDI vs 0\n",
    "\n",
    "- ANCOVA: beta0 + beta1[j] X1(nominal) + beta2 X2(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [5] Metric Predicted Variable with Multiple Nominal Predictors\n",
    "\n",
    "MANOVA: beta0 + beta1[j] X1(nominal) + beta2[k] X2(nominal) + beta3[j*k] X1*2[j*k]\n",
    "\n",
    "Y[i] distributed by N(u[i], ay)\n",
    "\n",
    "u[i] calculated from “beta0 + beta1[j] X1[i](nominal) + beta2[k] X2[i](nominal) + beta3[j*k] X1*2[i][j*k]”\n",
    "\n",
    "beta0 distributed by N(M0, S0)\n",
    "\n",
    "For beta1 in jth distributed by N(0, a-beta1)\n",
    "\n",
    "For beta2 in kth distributed by N(0, a-beta2)\n",
    "\n",
    "For beta3 in j*kth distributed by N(0, a-beta3)\n",
    "\n",
    "ay distributed by Uni(L, H)\n",
    "\n",
    "L, H, M0, S0 are constants\n",
    "\n",
    "a-beta1, a-beta2, a-beta3 are constant / small-strong shrinkage\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[A]_u[B]_Diff) HDI vs 0  Main effect\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[A1]_u[A2]_vs_u[B]) HDI vs 0  Interaction effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [6] Dichotomous Predicted Variable (As logistic regression)\n",
    "\n",
    "- Logistic Regression: Logistic( beta0 + beta[j] X[j](metric)) \n",
    "\n",
    "Y[i] distributed by dbern(u[i])\n",
    "\n",
    "u[i] calculated from “Logistic( beta0 + beta[j] X[j]) ” *Log(link func)\n",
    "\n",
    "beta0 distributed by N(M0, S0) \n",
    "\n",
    "For beta in jth distrusted by N(Mi, Si)\n",
    "\n",
    "M0, S0, Mi, Si are constants\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[i]) – prob() – Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression: Logistic( beta0 + beta1[j] X1[j](nominal))\n",
    "\n",
    "Y[i|j] distributed by Binominal(u[i|j]) ** computation efficient\n",
    "\n",
    "u[i|j] distributed by Beta(w[j], k)\n",
    "\n",
    "k distributed by Gamma(Sk, Rk)\n",
    "\n",
    "For w[j] in jth calculated from “Logistic( beta0 + beta[j] X[j]) ” *Log(link func)\n",
    "\n",
    "beta0 distributed by N(M0, S0) \n",
    "\n",
    "For beta in jth distrusted by N(0, a-beta)\n",
    "\n",
    "M0, S0, Sk, Rk are constants\n",
    "\n",
    "a-beta is constant / small-strong shrinkage\n",
    "\n",
    "Evaluation: MCMC – Posterior(u[i]) – prob() - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [7] Nominal Predicted Variable\n",
    "\n",
    "- Multinomial Logistic Regression (Soft-Max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conditional Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [8] Ordinal Predicted Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [9] Count Predicted Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
