{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Deep learning (also known as deep structured learning, hierarchical learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high level abstractions in data. It solves this central problem in representation learning by introducing representations that are expressed in terms of others, simpler representations. Deep learning enables the computer to build complex concepts out of simpler concepts.\n",
    "\n",
    "#### Computational Graphs\n",
    "\n",
    "It maps inputs to the outputs where each node performs an operation. Depth is the length of the longest path from input to output but depends on the definition of what consititutes a possible computaional step. Can be a calculation level or on the model level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "                                                         ###################\n",
    "                                                         #     Output      #\n",
    "                                                         #                 #\n",
    "                                                         ###################\n",
    "                                                                  |\n",
    "                                                                  |\n",
    "#                 ###############      ###############   ###################\n",
    "                  #   Output    #      #   Output    #   # Mapping from    #\n",
    "                  #             #      #             #   # Features        #\n",
    "                  ###############      ###############   ###################\n",
    "                         |                    |                   |\n",
    "                         |                    |                   |\n",
    "                         |                    |                   |\n",
    "###############   ###############      ###############   #####################\n",
    "#   Output    #   # Mapping from#      # Mapping from#   # Additional layers # ------ Special for\n",
    "#             #   # Features    #      # Features    #   # of more abstract f#         deep learning         \n",
    "###############   ###############      ###############   #####################\n",
    "       |                 |                    |                   |\n",
    "       |                 |                    |                   |\n",
    "###############   ###############      ###############   ###################\n",
    "# Hand-Design #   # Hand-Design #      # Features    #   # Simple Features #\n",
    "# Program     #   # Features    #      #             #   #                 #\n",
    "###############   ###############      ###############   ###################\n",
    "       |                 |                    |                   |\n",
    "       |                 |                    |                   |\n",
    "###############   ###############      ###############   ###################\n",
    "#  Input      #   #  Input      #      #    Input    #   #      Input      #\n",
    "###############   ###############      ###############   ###################\n",
    "                                                           \"Deep Learning\"\n",
    "\"Rule-based\"     \"Classic Machine\"     -------------------------------------\n",
    "  \"System\"          \"Learning\"              \"Representation Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## >>>>> Mathmetic Background (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Linear Algebra\n",
    "\n",
    "#### Scalars\n",
    "\n",
    "\n",
    "#### Vectors\n",
    "\n",
    "\n",
    "#### Matrices\n",
    "\n",
    "\n",
    "#### Tensors\n",
    "\n",
    "\n",
    "#### Multiplying Matrics and Vectors\n",
    "\n",
    "\n",
    "#### Identity Matrix / Inverse Matrix\n",
    "\n",
    "\n",
    "#### Linear Dependence and Span\n",
    "\n",
    "\n",
    "#### Norms\n",
    "\n",
    "\n",
    "#### Special Matrics and Vectors\n",
    "\n",
    "\n",
    "#### Eigen decomposition\n",
    "\n",
    "#### Singular Value Decomposition\n",
    "\n",
    "#### The Moore-Penrose Pseudoinverse\n",
    "\n",
    "\n",
    "#### The Trace Operator\n",
    "\n",
    "\n",
    "#### The Determinant\n",
    "\n",
    "\n",
    "\n",
    "## [2] Probability and Information Theory\n",
    "\n",
    "#### Why Probability?\n",
    "\n",
    "\n",
    "#### Random Variables\n",
    "\n",
    "\n",
    "#### Probability Distribution\n",
    "\n",
    "- Mass Function\n",
    "\n",
    "\n",
    "- Density Function\n",
    "\n",
    "#### Marginal Probability\n",
    "\n",
    "\n",
    "#### Conditional Probability\n",
    "\n",
    "\n",
    "#### The Chain Rule of Conditional Probabilities\n",
    "\n",
    "\n",
    "#### Independence and Conditional Independence\n",
    "\n",
    "\n",
    "#### Expectation, Variance and Covariance\n",
    "\n",
    "\n",
    "#### Common Probability Distributions\n",
    "\n",
    "- Bernoulli Distribution\n",
    "\n",
    "- Multinoulli Distribution\n",
    "\n",
    "- Gaussian Distribution\n",
    "\n",
    "- Exponential Distribution\n",
    "\n",
    "- Laplace Distribution\n",
    "\n",
    "- Dirac Distribution\n",
    "\n",
    "- Empirical Distribution\n",
    "\n",
    "- Mixtures of Distribution\n",
    "\n",
    "\n",
    "#### Useful Properties of Common Functions\n",
    "\n",
    "\n",
    "\n",
    "#### Bayes' Rules\n",
    "\n",
    "\n",
    "\n",
    "#### Technical Details of Continuous Variables\n",
    "\n",
    "\n",
    "#### Information Theory\n",
    "\n",
    "\n",
    "#### Kullback-Leibler (KL) divergence\n",
    "\n",
    "\n",
    "#### Structured Probablistic Models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [3] Numerical Computation\n",
    "\n",
    "#### Overflow and Underflow\n",
    "\n",
    "\n",
    "#### Poor Conditioning\n",
    "\n",
    "\n",
    "#### Gradient-Based Optimization\n",
    "\n",
    "- Basic Concepts\n",
    "\n",
    "\n",
    "- Beyond the Gradient: Jacobian and Hessian Matrices\n",
    "\n",
    "\n",
    "#### Constrained Optimization\n",
    "\n",
    "\n",
    "- Example: Linear Least Squares\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [4] Machine Learning Basics\n",
    "\n",
    "\n",
    "### Learning Algorithms\n",
    "\n",
    "#### (1) The Task, T\n",
    "\n",
    "- Classification\n",
    "\n",
    "\n",
    "- Classification with missing inputs\n",
    "\n",
    "\n",
    "- Regression\n",
    "\n",
    "\n",
    "- Transcription\n",
    "\n",
    "\n",
    "- Machine translation\n",
    "\n",
    "\n",
    "- Structured output\n",
    "\n",
    "\n",
    "- Anomaly detection\n",
    "\n",
    "\n",
    "- Synthesis and sampling\n",
    "\n",
    "\n",
    "- Imputation of missing values\n",
    "\n",
    "\n",
    "- Denoising\n",
    "\n",
    "\n",
    "- Density estimation or probability mass function estimation\n",
    "\n",
    "\n",
    "#### (2) The performance Measure, P\n",
    "\n",
    "\n",
    "#### (3) The Experience, E\n",
    "\n",
    "- Unsupervised Learning Algorithms\n",
    "\n",
    "\n",
    "\n",
    "- Supervised Learning Algorithms\n",
    "\n",
    "\n",
    "### Capacity, Overfitting and Underfitting\n",
    "\n",
    "\n",
    "- Capacity\n",
    "\n",
    "\n",
    "- Overfitting\n",
    "\n",
    "\n",
    "- Underfitting\n",
    "\n",
    "\n",
    "- The No Free Lunch Theorem\n",
    "\n",
    "\n",
    "- Regularization\n",
    "\n",
    "\n",
    "\n",
    "### Hyperparameters and Validation Sets\n",
    "\n",
    "- Validation Sets\n",
    "\n",
    "\n",
    "- Cross Validation Sets\n",
    "\n",
    "\n",
    "### Estimators, Bias and Variance\n",
    "\n",
    "- Point Estimation\n",
    "\n",
    "\n",
    "- Bias\n",
    "\n",
    "\n",
    "- Variance and Standard Error\n",
    "\n",
    "\n",
    "- Trading off Bias and Variance to Minimize Mean Squared Error\n",
    "\n",
    "\n",
    "### Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "- Basic\n",
    "\n",
    "\n",
    "- Conditional Log-Likelihood and Mean Squared Error\n",
    "\n",
    "\n",
    "- Properties of Maximum Likelihood\n",
    "\n",
    "\n",
    "### Bayesian Statistics\n",
    "\n",
    "- Basic\n",
    "\n",
    "\n",
    "- Maximum A Posteriori (MAP) Estimation\n",
    "\n",
    "\n",
    "### Supervised Learning Algorithms\n",
    "\n",
    "- Basic Concept\n",
    "\n",
    "\n",
    "### Unsupervised Learning Algorithms\n",
    "\n",
    "- Basic Concept\n",
    "\n",
    "\n",
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "\n",
    "\n",
    "### Building a Machine Learning Algorithm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# --------------------------------------------------------------------------------------------\n",
    "\n",
    "## Challenges Motivating Deep Learning **\n",
    "\n",
    "#### The Curse of Dimensionality\n",
    "\n",
    "\n",
    "#### Local Constancy and Smoothness Regularization\n",
    "\n",
    "\n",
    "#### Manifold Learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>>>>> Deep Networks: Modern Practices (3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>>>>> Deep Learning Research (4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
