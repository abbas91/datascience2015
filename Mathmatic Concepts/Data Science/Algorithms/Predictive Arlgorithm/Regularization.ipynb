{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "Regularization, in mathematics and statistics and particularly in the fields of machine learning and inverse problems, refers to a process of introducing additional information in order to solve an ill-posed problem or to prevent overfitting. You penalize your loss function by adding a multiple of an L1L1 (LASSO[2]) or an L2L2 (Ridge[3]) norm of your weights vector ww (it is the vector of the learned parameters in your linear regression). regularization artificially discourages complex or extreme explanations of the world even if they fit the what has been observed better. The idea is that such explanations are unlikely to generalize well to the future; they may happen to explain a few data points from the past well, but this may just be because of accidents of the sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Models Pros & Cons\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "#### Ridge Regressions (L2)\n",
    "- Big O Notation (Cost Function):\n",
    "\n",
    "Pros: Work best when least square estimate has high variance; Deal with high-dimensional data but shrink coefficients; If many Ps contribute Y, Ridge is good; Deal multi-colinearity; \n",
    "\n",
    "Cons: No feature selection performed; Good for grouping (if some features identical, coefficients are same)\n",
    "\n",
    "#### LASSO Regressions (L1)\n",
    "- Big O Notation (Cost Function):\n",
    "\n",
    "Pros: Work best when least square estimate has high variance; Deal exetremly well with high-dimensional data but shrink coefficients; If only a few feature actually useful, LASSO is good; Deal multi-colinearity; \n",
    "\n",
    "Cons: Feature selection performed; Good for elimiating travil features; If groups highly correlated features, pick one, others shrink to 0; \n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------- Ridge Regressions (L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wiki Definitation: \n",
    "L2 regularization. {lambda X beta^2}\n",
    "#### Input Data: \n",
    "X(Numeric) / X(Categorical)\n",
    "#### Initial Parameters: \n",
    "lambda = shrink parameter [infinite: null model <--> 0:least square]\n",
    "#### Cost Function: \n",
    "Add panelity term into the RSS minimization \n",
    "#### Process Flow: \n",
    "Standarize features ->\n",
    "Shrink coefficients towards 0 but never at 0 (Shrink by %)\n",
    "#### Evaluation Methods: \n",
    "\n",
    "#### Tips: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- R\n",
    "library(glmnet)\n",
    "\n",
    "# Create X matrix and Y vector\n",
    "x <- model.matrix(Y ~ . , data)[, -1]\n",
    "Y <- data$Y\n",
    "\n",
    "# Ridge Regression\n",
    "grid <- 10^seq(10, -2, length = 100)\n",
    "table.ridge <- glmnet(x, y, alpha=0, lambda = grid) # alpha = 0 ridge, 1 lasso\n",
    "\n",
    "# See a lambda value in the grid\n",
    "table.ridge$lambda[3] # 1-100\n",
    "coef(table.ridge)[,3] # 1-100\n",
    "sqrt(sum(coef(table.ridge)[-1,3]^2))\n",
    "\n",
    "# Get coefficients for a new lambda value\n",
    "predict(table.ridge, S=[newvale], type=\"coefficients\")[1:20,] # top 20 features\n",
    "\n",
    "# Croos validate to find the best lambda\n",
    "set.seed(10)\n",
    "table.cv <- cv.glmnet(trainX, trainY, alpha=0)\n",
    "best.lam <- table.cv$lambda.min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------- LASSO Regressions (L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wiki Definitation: \n",
    "L1 regularization. {lambda X |beta|}\n",
    "#### Input Data: \n",
    "X(Numeric) / X(Categorical)\n",
    "#### Initial Parameters: \n",
    "lambda = shrink parameter [infinite: null model <--> 0:least square]\n",
    "#### Cost Function: \n",
    "Add panelity term into the RSS minimization \n",
    "#### Process Flow: \n",
    "Standarize features ->\n",
    "Shrink coefficients towards 0 some features will be at 0 (Shrink by #)\n",
    "#### Evaluation Methods: \n",
    "\n",
    "#### Tips: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- R\n",
    "\n",
    "library(glmnet)\n",
    "table.lasso = glmnet(trainX, trainY, alpha=1, lambda=grid) # alpha = 1 lasso\n",
    "\n",
    "# CV\n",
    "set.seed(10)\n",
    "table.cv <- cv.glmnet(trainX, trainY, alpha=1)\n",
    "best.lam <- table.cv$lambda.min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
